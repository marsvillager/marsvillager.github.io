import{_ as n,o as t,c as e,O as l,z as s,a}from"./chunks/framework.aacc0fa0.js";const T=JSON.parse('{"title":"Background","description":"","frontmatter":{},"headers":[],"relativePath":"Floating Point.md"}'),m={name:"Floating Point.md"},i=l('<div class="info custom-block"><p class="custom-block-title">INFO</p><p>笔记</p></div><h1 id="background" tabindex="-1">Background <a class="header-anchor" href="#background" aria-label="Permalink to &quot;Background&quot;">​</a></h1><p>在深度学习硬件崛起之前，大多数的科学计算都是是基于 IEEE Float32 和 IEEE Float64 的。 随着深度学习的发展和 AI 处理器的演进，大家发现在 training 和 inference 的过程中，可以通过降低浮点运算的精度来有效的提升运行速度，功耗和芯片面积。那么，这给厂商提供了足够的自由度，来设计自己的浮点类型，从而取得 AI 系统性能和精度的平衡。</p><p>模型规模的持续扩大，导致模型训练和部署所需求的算力和功耗持续的扩张。面对算力的挑战，降低精度是一把利器，从最初的 FP32，到 16-bit 的 FP 的推出 （FP16和BF16），和一些定制的浮点类型的推出，如 TF32 等等。</p><h2 id="浮点数" tabindex="-1">浮点数 <a class="header-anchor" href="#浮点数" aria-label="Permalink to &quot;浮点数&quot;">​</a></h2><p>浮点数由三部分组成：符号位（sign）、指数部分（exponent）、尾数部分（mantissa）</p>',6),r=s("p",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mo",null,"("),s("mo",null,"−"),s("mn",null,"1"),s("msup",null,[s("mo",null,")"),s("mrow",null,[s("mi",null,"s"),s("mi",null,"i"),s("mi",null,"g"),s("mi",null,"n")])]),s("mo",null,"×"),s("msup",null,[s("mn",null,"2"),s("mrow",null,[s("mi",null,"e"),s("mi",null,"x"),s("mi",null,"p"),s("mi",null,"o"),s("mi",null,"n"),s("mi",null,"e"),s("mi",null,"n"),s("mi",null,"t"),s("mo",null,"−"),s("mi",null,"b"),s("mi",null,"i"),s("mi",null,"a"),s("mi",null,"s")])]),s("mo",null,"×"),s("mn",null,"1"),s("mi",{mathvariant:"normal"},"."),s("mi",null,"m"),s("mi",null,"a"),s("mi",null,"n"),s("mi",null,"t"),s("mi",null,"i"),s("mi",null,"s"),s("mi",null,"s"),s("mi",null,"a")]),s("annotation",{encoding:"application/x-tex"},"(-1)^{sign} \\times 2^{exponent - bias} \\times 1.mantissa")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.849108em"}}),s("span",{class:"strut bottom",style:{height:"1.099108em","vertical-align":"-0.25em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mopen"},"("),s("span",{class:"mord"},"−"),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.363em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle uncramped"},[s("span",{class:"mord scriptstyle uncramped"},[s("span",{class:"mord mathit"},"s"),s("span",{class:"mord mathit"},"i"),s("span",{class:"mord mathit",style:{"margin-right":"0.03588em"}},"g"),s("span",{class:"mord mathit"},"n")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mbin"},"×"),s("span",{class:"mord"},[s("span",{class:"mord mathrm"},"2"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.363em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle uncramped"},[s("span",{class:"mord scriptstyle uncramped"},[s("span",{class:"mord mathit"},"e"),s("span",{class:"mord mathit"},"x"),s("span",{class:"mord mathit"},"p"),s("span",{class:"mord mathit"},"o"),s("span",{class:"mord mathit"},"n"),s("span",{class:"mord mathit"},"e"),s("span",{class:"mord mathit"},"n"),s("span",{class:"mord mathit"},"t"),s("span",{class:"mbin"},"−"),s("span",{class:"mord mathit"},"b"),s("span",{class:"mord mathit"},"i"),s("span",{class:"mord mathit"},"a"),s("span",{class:"mord mathit"},"s")])])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mbin"},"×"),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mord mathrm"},"."),s("span",{class:"mord mathit"},"m"),s("span",{class:"mord mathit"},"a"),s("span",{class:"mord mathit"},"n"),s("span",{class:"mord mathit"},"t"),s("span",{class:"mord mathit"},"i"),s("span",{class:"mord mathit"},"s"),s("span",{class:"mord mathit"},"s"),s("span",{class:"mord mathit"},"a")])])])],-1),o=s("ul",null,[s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mi",null,"b"),s("mi",null,"i"),s("mi",null,"a"),s("mi",null,"s")]),s("annotation",{encoding:"application/x-tex"},"bias")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.69444em"}}),s("span",{class:"strut bottom",style:{height:"0.69444em","vertical-align":"0em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mord mathit"},"b"),s("span",{class:"mord mathit"},"i"),s("span",{class:"mord mathit"},"a"),s("span",{class:"mord mathit"},"s")])])]),a(" 决定了数的取值范围，默认值为 127")]),s("li",null,"规定尾数部分最高位必须是 1，1 不保存就可以节省出 1 位用于提高精度，因此最高位的 1 是隐含的（Implied）")],-1),c=s("h3",{id:"_1-十进制整数-17-fp32",tabindex:"-1"},[a("（1）十进制整数 17 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mo",null,"→")]),s("annotation",{encoding:"application/x-tex"},"\\rightarrow")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.36687em"}}),s("span",{class:"strut bottom",style:{height:"0.36687em","vertical-align":"0em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mrel"},"→")])])]),a(" Fp32 "),s("a",{class:"header-anchor",href:"#_1-十进制整数-17-fp32","aria-label":'Permalink to "（1）十进制整数 17 $\\rightarrow$ Fp32"'},"​")],-1),p=s("ul",null,[s("li",null,"sign = (0)2"),s("li",null,[a("exponent = (10000011)2 "),s("ul",null,[s("li",null,"exponent - bias = (128 + 2 + 1) - 127 = 4")])]),s("li",null,"mantissa = (00010000……)2")],-1),u=s("p",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mo",null,"("),s("mo",null,"−"),s("mn",null,"1"),s("msup",null,[s("mo",null,")"),s("mn",null,"0")]),s("mo",null,"×"),s("msup",null,[s("mn",null,"2"),s("mn",null,"4")]),s("mo",null,"×"),s("mo",null,"("),s("mn",null,"1"),s("mi",{mathvariant:"normal"},"."),s("mn",null,"0"),s("mn",null,"0"),s("mn",null,"0"),s("mn",null,"1"),s("mo",null,")"),s("mn",null,"2"),s("mo",null,"="),s("mo",null,"("),s("mn",null,"1"),s("mn",null,"0"),s("mn",null,"0"),s("mn",null,"0"),s("mn",null,"1"),s("mo",null,")"),s("mn",null,"2"),s("mo",null,"="),s("mn",null,"1"),s("mn",null,"7")]),s("annotation",{encoding:"application/x-tex"},"(-1)^0 \\times 2^4 \\times (1.0001)2 = (10001)2 = 17")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.8141079999999999em"}}),s("span",{class:"strut bottom",style:{height:"1.064108em","vertical-align":"-0.25em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mopen"},"("),s("span",{class:"mord"},"−"),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.363em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle uncramped"},[s("span",{class:"mord mathrm"},"0")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mbin"},"×"),s("span",{class:"mord"},[s("span",{class:"mord mathrm"},"2"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.363em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle uncramped"},[s("span",{class:"mord mathrm"},"4")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mbin"},"×"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mord mathrm"},"."),s("span",{class:"mord mathrm"},"0"),s("span",{class:"mord mathrm"},"0"),s("span",{class:"mord mathrm"},"0"),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mclose"},")"),s("span",{class:"mord mathrm"},"2"),s("span",{class:"mrel"},"="),s("span",{class:"mopen"},"("),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mord mathrm"},"0"),s("span",{class:"mord mathrm"},"0"),s("span",{class:"mord mathrm"},"0"),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mclose"},")"),s("span",{class:"mord mathrm"},"2"),s("span",{class:"mrel"},"="),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mord mathrm"},"7")])])])],-1),h=s("h3",{id:"_2-十进制数-3-25-fp32",tabindex:"-1"},[a("（2）十进制数 3.25 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mo",null,"→")]),s("annotation",{encoding:"application/x-tex"},"\\rightarrow")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.36687em"}}),s("span",{class:"strut bottom",style:{height:"0.36687em","vertical-align":"0em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mrel"},"→")])])]),a(" Fp32 "),s("a",{class:"header-anchor",href:"#_2-十进制数-3-25-fp32","aria-label":'Permalink to "（2）十进制数 3.25 $\\rightarrow$ Fp32"'},"​")],-1),d=s("ul",null,[s("li",null,"sign = (0)2"),s("li",null,[a("exponent = (10000000)2 "),s("ul",null,[s("li",null,"exponent - bias = 128 - 127 = 1")])]),s("li",null,"mantissa = (10100000……)2")],-1),b=s("p",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",null,[s("semantics",null,[s("mrow",null,[s("mo",null,"("),s("mo",null,"−"),s("mn",null,"1"),s("msup",null,[s("mo",null,")"),s("mn",null,"0")]),s("mo",null,"×"),s("msup",null,[s("mn",null,"2"),s("mn",null,"1")]),s("mo",null,"×"),s("mo",null,"("),s("mn",null,"1"),s("mi",{mathvariant:"normal"},"."),s("mn",null,"1"),s("mn",null,"0"),s("mn",null,"1"),s("mo",null,")"),s("mn",null,"2"),s("mo",null,"="),s("mo",null,"("),s("mn",null,"1"),s("mn",null,"1"),s("mi",{mathvariant:"normal"},"."),s("mn",null,"0"),s("mn",null,"1"),s("mo",null,")"),s("mn",null,"2"),s("mo",null,"="),s("mn",null,"3"),s("mi",{mathvariant:"normal"},"."),s("mn",null,"2"),s("mn",null,"5")]),s("annotation",{encoding:"application/x-tex"},"(-1)^0 \\times 2^1 \\times (1.101)2 = (11.01)2 = 3.25")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"strut",style:{height:"0.8141079999999999em"}}),s("span",{class:"strut bottom",style:{height:"1.064108em","vertical-align":"-0.25em"}}),s("span",{class:"base textstyle uncramped"},[s("span",{class:"mopen"},"("),s("span",{class:"mord"},"−"),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.363em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle uncramped"},[s("span",{class:"mord mathrm"},"0")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mbin"},"×"),s("span",{class:"mord"},[s("span",{class:"mord mathrm"},"2"),s("span",{class:"vlist"},[s("span",{style:{top:"-0.363em","margin-right":"0.05em"}},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),s("span",{class:"reset-textstyle scriptstyle uncramped"},[s("span",{class:"mord mathrm"},"1")])]),s("span",{class:"baseline-fix"},[s("span",{class:"fontsize-ensurer reset-size5 size5"},[s("span",{style:{"font-size":"0em"}},"​")]),a("​")])])]),s("span",{class:"mbin"},"×"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mord mathrm"},"."),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mord mathrm"},"0"),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mclose"},")"),s("span",{class:"mord mathrm"},"2"),s("span",{class:"mrel"},"="),s("span",{class:"mopen"},"("),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mord mathrm"},"."),s("span",{class:"mord mathrm"},"0"),s("span",{class:"mord mathrm"},"1"),s("span",{class:"mclose"},")"),s("span",{class:"mord mathrm"},"2"),s("span",{class:"mrel"},"="),s("span",{class:"mord mathrm"},"3"),s("span",{class:"mord mathrm"},"."),s("span",{class:"mord mathrm"},"2"),s("span",{class:"mord mathrm"},"5")])])])],-1),f=l('<h2 id="fp64-float-point-双精度浮点数" tabindex="-1">FP64（Float Point，双精度浮点数） <a class="header-anchor" href="#fp64-float-point-双精度浮点数" aria-label="Permalink to &quot;FP64（Float Point，双精度浮点数）&quot;">​</a></h2><ul><li>符号位 1 bit</li><li>指数位 11 bit <ul><li>bias = 1023</li></ul></li><li>尾数位 52 bit</li></ul><h2 id="fp32-单精度浮点数" tabindex="-1">FP32（单精度浮点数） <a class="header-anchor" href="#fp32-单精度浮点数" aria-label="Permalink to &quot;FP32（单精度浮点数）&quot;">​</a></h2><ul><li>符号位 1 bit</li><li>指数位 8 bit <ul><li>bias = 127</li></ul></li><li>尾数位 23 bit</li></ul><h2 id="tf32-tensor-float" tabindex="-1">TF32（Tensor Float） <a class="header-anchor" href="#tf32-tensor-float" aria-label="Permalink to &quot;TF32（Tensor Float）&quot;">​</a></h2><p>TF32 是由 Nvidia 提出，首发于 A100 GPU 中。 TF32 的名字会有点 confusing，其实它并没有 32-bit，相反它只有 19-bit，更应该称为 BF19。</p><h2 id="fp16-半精度浮点数" tabindex="-1">FP16（半精度浮点数） <a class="header-anchor" href="#fp16-半精度浮点数" aria-label="Permalink to &quot;FP16（半精度浮点数）&quot;">​</a></h2><ul><li>符号位 1 bit</li><li>指数位 5 bit <ul><li>bias = 15</li></ul></li><li>尾数位 10 bit</li></ul><h2 id="bf16-bfloat" tabindex="-1">BF16（BFloat） <a class="header-anchor" href="#bf16-bfloat" aria-label="Permalink to &quot;BF16（BFloat）&quot;">​</a></h2><p>BF16 的提出是为了解决 FP16 在 deep learning 应用中遇到的一些问题。</p><ol><li>BF16 和 FP32 的 range 是一致的，远大于 FP16 的 6.5e4。缺点则是 BF16 只有 7 个 bit 的 mantissa，精度上是低于 FP16。</li><li>BF16 基本上可以看作成一个“截断”版的 FP32，两者之间的转换是非常直接，其实现电路也会非常简单。 BF16 和 FP32 之间的转换在 training 的过程中是会频繁发生的，BF16 的使用能有效的降低电路的面积。</li></ol><p>BF16 首先是在 Google 的 TPU 中得到支持，其后在业界得到了广泛的支持。当前主流的硬件厂商都对 BF16 做了深度的优化实现。</p><h2 id="fp8" tabindex="-1">FP8 <a class="header-anchor" href="#fp8" aria-label="Permalink to &quot;FP8&quot;">​</a></h2><p>2022年，Nvidia 发布的最新一代高性能 GPU 架构：H100。H100 TensorCore 中引入了一种新的浮点类型 FP8。相较于 FP16/BF16，FP8 能取得到 2x 的性能提升，4096 MAC/cycle 的水平。</p><p><img src="https://pic1.zhimg.com/80/v2-e0349edbb465cf3abf12cc65d5479ac4_1440w.jpg" alt="img1"></p><p><img src="https://img-blog.csdnimg.cn/0f15629ed5204216ab3279c1855c9532.png" alt="img2"></p><p>有两种形式，E5M2 和 E4M3</p><ul><li>E5M2 <ul><li>指数位 5 bit</li><li>尾数位 2 bit</li></ul></li><li>E4M3 <ul><li>指数位 4 bit</li><li>尾数位 3 bit</li></ul></li></ul><h2 id="hfp8" tabindex="-1">HFP8 <a class="header-anchor" href="#hfp8" aria-label="Permalink to &quot;HFP8&quot;">​</a></h2><p>Hybrid FP8：forward 的时候用 FP-1-4-3，backward的时候用 FP-1-5-2。forward 的时候更关注精度，backward 的时候更注重范围。这样的话，HFP8 就能够在训练的过程中获得接近 FP32 的表现。</p><h2 id="conclusion" tabindex="-1">Conclusion <a class="header-anchor" href="#conclusion" aria-label="Permalink to &quot;Conclusion&quot;">​</a></h2><ul><li>不同的浮点类型可以给算法和应用带来非常大的自由度，可以选择最合适的设计来满足功耗、性能、精度的要求。尤其对于那些从应用到芯片都自己开发的厂商，比如 MSFP 和 Tesla Dojo</li><li>硬币的另一面则是不同的浮点类型可能并不好移植到别的硬件，比如 CFloat8 就很难在 Nvidia 的硬件上得到加速；同样，TF32 可能只能在 Nvidia 上得到支持</li></ul><h2 id="reference" tabindex="-1">Reference <a class="header-anchor" href="#reference" aria-label="Permalink to &quot;Reference&quot;">​</a></h2><ul><li><a href="https://zhuanlan.zhihu.com/p/449857213" target="_blank" rel="noreferrer">https://zhuanlan.zhihu.com/p/449857213</a></li><li><a href="https://blog.csdn.net/weixin_42330305/article/details/127518011" target="_blank" rel="noreferrer">https://blog.csdn.net/weixin_42330305/article/details/127518011</a></li></ul>',24),g=[i,r,o,c,p,u,h,d,b,f];function x(_,F,z,P,y,k){return t(),e("div",null,g)}const q=n(m,[["render",x]]);export{T as __pageData,q as default};
